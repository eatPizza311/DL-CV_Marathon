{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 知識點\n",
    "- Kernel 用來學習圖像的特徵，張數 (filters) 決定學習的參數量，大小決定特徵接受域 (Receptive field)，也就是看到特徵的大小。\n",
    "    - 起始值：Kernel 中的值就是我們要訓練的權重，通常用常態分佈隨機產生，再經由訓練更新。\n",
    "    - 張數：控制張數主要就是控制學習的參數量，常見是16、32 或 64，如果使用16張 Kernels 就能達到很好的效果，也就不需要浪費額外的參數去增加學習與計算量。\n",
    "    - 大小影響：Receptive field 直觀來說就是 Kernel 提取資訊的尺度，現在普遍流行的方式是選用不同大小的 Kernel 對圖像做卷積後，再把輸出的 Feature maps 合併或平均。 \n",
    "\n",
    "> 有人提出兩層 3x3 的Kernel 卷積與一層的 5x5 Kernel 卷積擁有相近的Receptive field，並且使用較少的參數量，因此大家不妨去嘗試看看不同組合的效果。\n",
    "\n",
    "- 奇數 Kernel 有幾個先天上的優勢，第一個原因是由於奇數卷積核有中心點，較容易對齊確認位置資訊，再者是因為奇數卷積核能確保 Padding 的對稱性。\n",
    "\n",
    "- 參數量\n",
    "    - 全連接網路 (FCN): inputs x outputs + outputs(bias)，優點是可以保留語意資訊。\n",
    "    - 卷積網路 (CNN): (kernel_H x kernel_W x channels + 1) x kernel_number，優點是可以保留空間資訊。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "f6jN0Y8x4gNA"
   },
   "source": [
    "## 『本次練習內容』\n",
    "#### 運用Keras搭建簡單的Dense Layer與 Convolution2D Layer，使用相同Neurons數量，計算總參數量相差多少。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 『本次練習目的』\n",
    "  #### 本次練習主要是要讓各位同學們了解CNN與FC層的參數使用量差異\n",
    "  #### Convolution2D有許多參數可以設置，之後章節會細談\n",
    "  #### 不熟Keras的學員們也可以藉此了解NN層的不同搭法"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tensorflow.keras.models import Model, Sequential\n",
    "from tensorflow.keras.layers import Convolution2D, Dense, Input, Flatten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 26, 26, 32)        320       \n",
      "=================================================================\n",
      "Total params: 320\n",
      "Trainable params: 320\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# 輸入照片的尺寸\n",
    "input_size = (28, 28, 1)\n",
    "\n",
    "# 建造一個一層的 CNN\n",
    "cnn_clf = Sequential([\n",
    "    Convolution2D(kernel_size=3, filters=32, input_shape=input_size)\n",
    "])\n",
    "\n",
    "#看看model結構\n",
    "print(cnn_clf.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> 320 = (3 x 3 x 1 + 1) x 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "flatten (Flatten)            (None, 784)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 288)               226080    \n",
      "=================================================================\n",
      "Total params: 226,080\n",
      "Trainable params: 226,080\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "#建造一個一層的FC層\n",
    "fc_clf = Sequential([\n",
    "    Flatten(input_shape=input_size),\n",
    "    Dense(288)\n",
    "])\n",
    "\n",
    "##看看model結構\n",
    "print(fc_clf.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 784)]             0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 288)               226080    \n",
      "=================================================================\n",
      "Total params: 226,080\n",
      "Trainable params: 226,080\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# 另一種建造法\n",
    "flatten_size = tuple([np.prod(input_size)])\n",
    "\n",
    "# 輸入為28*28*1攤平==784\n",
    "inputs = Input(shape=flatten_size)\n",
    "\n",
    "# CNN中用了(3*3*1)*32個神經元，我們這邊也用相同神經元數量\n",
    "x = Dense(288)(inputs)\n",
    "model = Model(inputs=inputs, outputs=x)\n",
    "\n",
    "# 看看model結構\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> 226080 = 784 x 288 + 288"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "CNN-計算參數量.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
